import ply.lex as lex
import ply.yacc as yacc
import os
import copy
from enum import Enum


class Transitions(Enum):
    EPSILON = 0

    def __repr__(self):
        if self.name == "EPSILON":
            return "\u03B5"
        return self.name

    def __str__(self):
        if self.name == "EPSILON":
            return "\u03B5"
        return self.name


class RegexParser:

    next_state = 0

    def __init__(self, **kw):
        self.debug = kw.get('debug', 0)
        self.names = {}
        try:
            modname = os.path.split(os.path.splitext(__file__)[0])[1] + "_" + self.__class__.__name__
        except:
            modname = "parser" + "_" + self.__class__.__name__
        self.debugfile = modname + ".dbg"
        self.tabmodule = modname + "_" + "parsetab"

        # Build the lexer and parser
        lex.lex(module=self, debug=self.debug)
        yacc.yacc(module=self,
                  debug=self.debug,
                  debugfile=self.debugfile,
                  tabmodule=self.tabmodule)
        self.next_state = 0

    @classmethod
    def new_state(cls):
        result = cls.next_state
        cls.next_state += 1
        return result

    def run(self, s):
        self.next_state = 0
        return self.normalize_nfa(yacc.parse(s))

    def normalize_nfa(self, nfa):
        """Converts the states to be sequential numbers, removing gaps.  This makes the
           tests slightly less brittle and makes the graphs nicer to look at

        """
        new_nfa = {}
        old_states = list(nfa['states'])
        state_mapping = {}
        next_state = 0
        old_states.sort()
        for i in old_states:
            state_mapping[i] = next_state
            next_state += 1

        new_nfa['states'] = set(range(len(old_states)))
        new_nfa['accepting_states'] = set()
        new_nfa['initial_states'] = set()
        new_nfa['transitions'] = {}
        new_nfa['alphabet'] = copy.deepcopy(nfa['alphabet'])

        for i in nfa['accepting_states']:
            new_nfa['accepting_states'].add(state_mapping[i])

        for i in nfa['initial_states']:
            new_nfa['initial_states'].add(state_mapping[i])

        for (s, c), dests in nfa['transitions'].items():
            new_nfa['transitions'][(state_mapping[s], c)] = {state_mapping[d] for d in dests}

        return new_nfa

    # Grammar for regex:
    # regex = exp $
    # exp      = term [|] exp      {push '|'}
    #          | term
    #          |                   empty?
    # term     = factor term       chain {add \x08}
    #          | factor
    # factor   = primary [*]       star {push '*'}
    #          | primary [+]       plus {push '+'}
    #          | primary [?]       optional {push '?'}
    #          | primary
    # primary  = \( exp \)
    #          | char              literal {push char}

    tokens = (
        'STAR', 'PLUS', 'OPTIONAL', 'LITERAL', 'LPAREN', 'RPAREN', 'ALTERNATE'
    )

    # Tokens

    t_STAR = r'\*'
    t_PLUS = r'\+'
    t_OPTIONAL = r'\?'
    t_LITERAL = r'[A-Za-z0-9_]'
    t_LPAREN = r'\('
    t_RPAREN = r'\)'
    t_ALTERNATE = r'\|'

    def t_error(self, t):
        print("Illegal character '%s'" % t.value[0])
        t.lexer.skip(1)

    # Parsing rules

    def p_exp(self, p):
        """
        exp : term ALTERNATE exp
            | term
        """
        if len(p) == 4:
            p[0] = self.alternate(p[1], p[3])
        else:
            p[0] = p[1]

    def p_term(self, p):
        """
        term : factor term
             | factor
        """
        if len(p) == 3:
            p[0] = self.concatenate(p[1], p[2])
        else:
            p[0] = p[1]

    def p_factor(self, p):
        """
        factor : primary STAR
               | primary PLUS
               | primary OPTIONAL
               | primary
        """
        if len(p) == 3:
            if p[2] == '*':
                p[0] = self.star(p[1])
            elif p[2] == '+':
                p[0] = self.plus(p[1])
            else:
                p[0] = self.optional(p[1])
        else:
            p[0] = p[1]

    def p_primary(self, p):
        """
        primary : LPAREN exp RPAREN
                | LITERAL
        """
        if len(p) == 4:
            p[0] = p[2]
        else:
            p[0] = self.single_element_nfa(p[1])

    def p_error(self, p):
        if p:
            print("Syntax error at '%s'" % p.value)
        else:
            print("Syntax error at EOF")

    def duplicate(self, nfa):
        """Creates a duplicate NFA with different state numbers"""
        state_mapping = {}
        for state in nfa['states']:
            state_mapping[state] = RegexParser.new_state()

        transitions = {}
        for (s, c), dests in nfa['transitions'].items():
            for d in dests:
                self.add_transition(transitions, state_mapping[s], c, state_mapping[d])

        return {
            'alphabet': copy.deepcopy(nfa['alphabet']),
            'states': {state_mapping[s] for s in nfa['states']},
            'transitions': transitions,
            'initial_states': {state_mapping[s] for s in nfa['initial_states']},
            'accepting_states': {state_mapping[s] for s in nfa['accepting_states']},
        }

    def plus(self, nfa):
        # Plus is equivalent to concatinating the nfa with a star version of
        # itself, i.e. a+ is equivalent to aa*
        new_state = RegexParser.new_state()
        transitions = copy.deepcopy(nfa['transitions'])
        for i in nfa['initial_states']:
            self.add_transition(transitions, new_state, Transitions.EPSILON, i)
        for a in nfa['accepting_states']:
            self.add_transition(transitions, a, Transitions.EPSILON, new_state)
        return {
            'states': nfa['states'].union([new_state]),
            'alphabet': nfa['alphabet'].union([Transitions.EPSILON]),
            'transitions': transitions,
            'initial_states': copy.deepcopy(nfa['initial_states']),
            'accepting_states': set([new_state]),
        }

    def star(self, nfa):
        new_state = RegexParser.new_state()
        transitions = copy.deepcopy(nfa['transitions'])
        for i in nfa['initial_states']:
            self.add_transition(transitions, new_state, Transitions.EPSILON, i)
        for a in nfa['accepting_states']:
            self.add_transition(transitions, a, Transitions.EPSILON, new_state)
        return {
            'states': nfa['states'].union([new_state]),
            'alphabet': nfa['alphabet'].union([Transitions.EPSILON]),
            'transitions': transitions,
            'initial_states': set([new_state]),
            'accepting_states': set([new_state]),
        }

    def alternate(self, left, right):
        new_start_state = RegexParser.new_state()
        transitions = copy.deepcopy({**left['transitions'], **right['transitions']})
        for i in left['initial_states'].union(right['initial_states']):
            self.add_transition(transitions, new_start_state, Transitions.EPSILON, i)
        return {
            'states': left['states'].union(right['states'], [new_start_state]),
            'alphabet': left['alphabet'].union(right['alphabet'], [Transitions.EPSILON]),
            'transitions': transitions,
            'initial_states': set([new_start_state]),
            'accepting_states': left['accepting_states'].union(right['accepting_states'])
        }

    def optional(self, nfa):
        """Optional is simple, make the initial states also final states, in
           addition to original final states"""
        new_start_state = RegexParser.new_state()
        new_final_state = RegexParser.new_state()
        transitions = copy.deepcopy(nfa['transitions'])
        for i in nfa['initial_states']:
            self.add_transition(transitions, new_start_state, Transitions.EPSILON, i)
        self.add_transition(transitions, new_start_state, Transitions.EPSILON, new_final_state)
        for a in nfa['accepting_states']:
            self.add_transition(transitions, a, Transitions.EPSILON, new_final_state)
        return {
            'states': nfa['states'].union([new_start_state, new_final_state]),
            'alphabet': nfa['alphabet'].union([Transitions.EPSILON]),
            'transitions': transitions,
            'initial_states': set([new_start_state]),
            'accepting_states': set([new_final_state]),
        }

    def add_transition(self, transitions, source, character, destination):
        transitions.setdefault((source, character), set()).add(destination)

    def concatenate(self, left, right):
        transitions = copy.deepcopy({**left['transitions'], **right['transitions']})
        for a in left['accepting_states']:
            for i in right['initial_states']:
                self.add_transition(transitions, a, Transitions.EPSILON, i)
        return {
            'alphabet': left['alphabet'].union(right['alphabet'], [Transitions.EPSILON]),
            'states': left['states'].union(right['states']),
            'transitions': transitions,
            'initial_states': copy.deepcopy(left['initial_states']),
            'accepting_states': copy.deepcopy(right['accepting_states']),
        }

    def single_element_nfa(self, literal):
        initial_state = RegexParser.new_state()
        accepting_state = RegexParser.new_state()
        transitions = {}
        transitions[(initial_state, literal)] = set([accepting_state])
        return {
            'alphabet': set([literal]),
            'states': set([initial_state, accepting_state]),
            'transitions': transitions,
            'initial_states': set([initial_state]),
            'accepting_states': set([accepting_state]),
        }
